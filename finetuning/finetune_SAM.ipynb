{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2cb0f6d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15825,
     "status": "ok",
     "timestamp": 1768499212567,
     "user": {
      "displayName": "Simone Iachino",
      "userId": "17661475359145447135"
     },
     "user_tz": -60
    },
    "id": "b2cb0f6d",
    "outputId": "7a62e5b5-c4c2-42d4-d692-174a788834bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Monta Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f01d26a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 12239,
     "status": "ok",
     "timestamp": 1768499224809,
     "user": {
      "displayName": "Simone Iachino",
      "userId": "17661475359145447135"
     },
     "user_tz": -60
    },
    "id": "9f01d26a",
    "outputId": "978f70f8-255b-4ac9-e44f-e4fe3b717241"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/semantic_correspondence.zip'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percorsi\n",
    "zip_su_drive = '/content/drive/MyDrive/semantic_correspondence.zip'\n",
    "zip_locale = '/content/semantic_correspondence.zip'\n",
    "cartella_destinazione = '/content/'\n",
    "\n",
    "# Copia lo zip in locale\n",
    "import shutil\n",
    "shutil.copy(zip_su_drive, zip_locale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aa7ad34",
   "metadata": {
    "executionInfo": {
     "elapsed": 20130,
     "status": "ok",
     "timestamp": 1768499244940,
     "user": {
      "displayName": "Simone Iachino",
      "userId": "17661475359145447135"
     },
     "user_tz": -60
    },
    "id": "2aa7ad34"
   },
   "outputs": [],
   "source": [
    "# Estrai lo zip\n",
    "import zipfile, os\n",
    "os.makedirs(cartella_destinazione, exist_ok=True)\n",
    "with zipfile.ZipFile(zip_locale, 'r') as z:\n",
    "    z.extractall(cartella_destinazione)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "992bd44a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4715,
     "status": "ok",
     "timestamp": 1768499249657,
     "user": {
      "displayName": "Simone Iachino",
      "userId": "17661475359145447135"
     },
     "user_tz": -60
    },
    "id": "992bd44a",
    "outputId": "307d7a25-f614-4878-efe2-62e9741283bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "# 5. Verify GPU\n",
    "import torch\n",
    "print(f\"\\n✓ GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No GPU'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "142b448d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 100,
     "status": "ok",
     "timestamp": 1768499249759,
     "user": {
      "displayName": "Simone Iachino",
      "userId": "17661475359145447135"
     },
     "user_tz": -60
    },
    "id": "142b448d",
    "outputId": "8ec7921e-894b-4b3e-9762-523cffa9ecde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan 15 17:47:32 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   46C    P8             10W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6a7bfb3",
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1768499249793,
     "user": {
      "displayName": "Simone Iachino",
      "userId": "17661475359145447135"
     },
     "user_tz": -60
    },
    "id": "a6a7bfb3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content/semantic_correspondence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28dae975",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1768499249816,
     "user": {
      "displayName": "Simone Iachino",
      "userId": "17661475359145447135"
     },
     "user_tz": -60
    },
    "id": "28dae975"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "def extract_dense_features(model, img_tensor, training=False):\n",
    "    \"\"\"Extract dense features from DINOv2 model given an input image tensor.\"\"\"\n",
    "    context = torch.no_grad() if not training else torch.enable_grad()\n",
    "\n",
    "    with context:\n",
    "        #get tokens\n",
    "        features_dict = model.forward_features(img_tensor)\n",
    "        patch_tokens = features_dict['x_norm_patchtokens']  # [B, N_patches, D]\n",
    "\n",
    "        #reshaping to dense feature map\n",
    "        B, N, D = patch_tokens.shape\n",
    "        H_patches = W_patches = int(N ** 0.5)  # per img 518x518 con patch 14: 37x37\n",
    "        dense_features = patch_tokens.reshape(B, H_patches, W_patches, D)\n",
    "    return dense_features\n",
    "\n",
    "\n",
    "def pixel_to_patch_coord(x, y, original_size, patch_size=14, resized_size=518):\n",
    "    \"\"\"convert pixel coordinates to patch coordinates\"\"\"\n",
    "    #scale to resized image\n",
    "    scale_x = resized_size / original_size[0]\n",
    "    scale_y = resized_size / original_size[1]\n",
    "    x_resized = x * scale_x\n",
    "    y_resized = y * scale_y\n",
    "\n",
    "    #compute patch coordinates\n",
    "    patch_x = int(x_resized // patch_size)\n",
    "    patch_y = int(y_resized // patch_size)\n",
    "\n",
    "    #clamp to valid range\n",
    "    max_patch = resized_size // patch_size - 1\n",
    "    patch_x = min(max(patch_x, 0), max_patch)\n",
    "    patch_y = min(max(patch_y, 0), max_patch)\n",
    "\n",
    "    return patch_x, patch_y\n",
    "\n",
    "\n",
    "def patch_to_pixel_coord(patch_x, patch_y, original_size, patch_size=14, resized_size=518):\n",
    "    \"\"\"Convert patch coordinates back to pixel coordinates with a centering strategy\"\"\"\n",
    "    #center of the patch in resized image\n",
    "    x_resized = patch_x * patch_size + patch_size / 2\n",
    "    y_resized = patch_y * patch_size + patch_size / 2\n",
    "\n",
    "    #scale back to original image size\n",
    "    scale_x = original_size[0] / resized_size\n",
    "    scale_y = original_size[1] / resized_size\n",
    "    x = x_resized * scale_x\n",
    "    y = y_resized * scale_y\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a495cd3",
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1768499249845,
     "user": {
      "displayName": "Simone Iachino",
      "userId": "17661475359145447135"
     },
     "user_tz": -60
    },
    "id": "1a495cd3"
   },
   "outputs": [],
   "source": [
    "\n",
    "base = '/content/semantic_correspondence/SPair71k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12380214",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8521195,
     "status": "ok",
     "timestamp": 1768511816192,
     "user": {
      "displayName": "Simone Iachino",
      "userId": "17661475359145447135"
     },
     "user_tz": -60
    },
    "id": "12380214",
    "outputId": "ff5afdaa-f6a6-43f4-c3e5-cdb0d7237d17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Results will be saved to: results_colab/SAM/lr_0.0001_t_5_blocks_2_20260115_175841\n",
      "\n",
      "Loading SPair-71k dataset...\n",
      "Training samples: 53340\n",
      "Val samples: 5384\n",
      "\n",
      "================================================================================\n",
      "FINETUNING WITH LAST 2 BLOCKS UNFROZEN\n",
      "================================================================================\n",
      "\n",
      "Loading SAM model...\n",
      "Unfrozen last 2 blocks of SAM image encoder. Final norm layer not found or accessible via 'neck.ln_final'.\n",
      "\n",
      "Trainable parameters: 14,195,456 / 93,735,472 (15.14%)\n",
      "\n",
      "============================================================\n",
      "STARTING TRAINING\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Epoch 1/1\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-2564884531.py:281: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "/tmp/ipython-input-2564884531.py:160: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100/53340, Loss: 4.9994\n",
      "Epoch 1, Batch 200/53340, Loss: 6.1317\n",
      "Epoch 1, Batch 300/53340, Loss: 5.9978\n",
      "Epoch 1, Batch 400/53340, Loss: 4.4947\n",
      "Epoch 1, Batch 500/53340, Loss: 4.3440\n",
      "Epoch 1, Batch 600/53340, Loss: 4.2927\n",
      "Epoch 1, Batch 700/53340, Loss: 5.1783\n",
      "Epoch 1, Batch 800/53340, Loss: 5.9043\n",
      "Epoch 1, Batch 900/53340, Loss: 4.2638\n",
      "Epoch 1, Batch 1000/53340, Loss: 3.9497\n",
      "Epoch 1, Batch 1100/53340, Loss: 5.0315\n",
      "Epoch 1, Batch 1200/53340, Loss: 4.7780\n",
      "Epoch 1, Batch 1300/53340, Loss: 4.8243\n",
      "Epoch 1, Batch 1400/53340, Loss: 4.8820\n",
      "Epoch 1, Batch 1500/53340, Loss: 3.1909\n",
      "Epoch 1, Batch 1600/53340, Loss: 4.2462\n",
      "Epoch 1, Batch 1700/53340, Loss: 3.7901\n",
      "Epoch 1, Batch 1800/53340, Loss: 3.7668\n",
      "Epoch 1, Batch 1900/53340, Loss: 4.6607\n",
      "Epoch 1, Batch 2000/53340, Loss: 3.3718\n",
      "Epoch 1, Batch 2100/53340, Loss: 3.2340\n",
      "Epoch 1, Batch 2200/53340, Loss: 4.0268\n",
      "Epoch 1, Batch 2300/53340, Loss: 4.6315\n",
      "Epoch 1, Batch 2400/53340, Loss: 4.3683\n",
      "Epoch 1, Batch 2500/53340, Loss: 3.8016\n",
      "Epoch 1, Batch 2600/53340, Loss: 3.6678\n",
      "Epoch 1, Batch 2700/53340, Loss: 3.3445\n",
      "Epoch 1, Batch 2800/53340, Loss: 3.9748\n",
      "Epoch 1, Batch 2900/53340, Loss: 3.6636\n",
      "Epoch 1, Batch 3000/53340, Loss: 4.6784\n",
      "Epoch 1, Batch 3100/53340, Loss: 4.6267\n",
      "Epoch 1, Batch 3200/53340, Loss: 4.2630\n",
      "Epoch 1, Batch 3300/53340, Loss: 3.7491\n",
      "Epoch 1, Batch 3400/53340, Loss: 3.7547\n",
      "Epoch 1, Batch 3500/53340, Loss: 2.4771\n",
      "Epoch 1, Batch 3600/53340, Loss: 3.8483\n",
      "Epoch 1, Batch 3700/53340, Loss: 3.5635\n",
      "Epoch 1, Batch 3800/53340, Loss: 3.4717\n",
      "Epoch 1, Batch 3900/53340, Loss: 3.6886\n",
      "Epoch 1, Batch 4000/53340, Loss: 3.7864\n",
      "Epoch 1, Batch 4100/53340, Loss: 3.1468\n",
      "Epoch 1, Batch 4200/53340, Loss: 5.8235\n",
      "Epoch 1, Batch 4300/53340, Loss: 4.2369\n",
      "Epoch 1, Batch 4400/53340, Loss: 3.3224\n",
      "Epoch 1, Batch 4500/53340, Loss: 3.4640\n",
      "Epoch 1, Batch 4600/53340, Loss: 2.8812\n",
      "Epoch 1, Batch 4700/53340, Loss: 4.2732\n",
      "Epoch 1, Batch 4800/53340, Loss: 4.7823\n",
      "Epoch 1, Batch 4900/53340, Loss: 3.0853\n",
      "Epoch 1, Batch 5000/53340, Loss: 3.0291\n",
      "Epoch 1, Batch 5100/53340, Loss: 2.1531\n",
      "Epoch 1, Batch 5200/53340, Loss: 2.5245\n",
      "Epoch 1, Batch 5300/53340, Loss: 3.1338\n",
      "Epoch 1, Batch 5400/53340, Loss: 2.6428\n",
      "Epoch 1, Batch 5500/53340, Loss: 3.3055\n",
      "Epoch 1, Batch 5600/53340, Loss: 2.2339\n",
      "Epoch 1, Batch 5700/53340, Loss: 2.8865\n",
      "Epoch 1, Batch 5800/53340, Loss: 3.6304\n",
      "Epoch 1, Batch 5900/53340, Loss: 3.9425\n",
      "Epoch 1, Batch 6000/53340, Loss: 4.0538\n",
      "Epoch 1, Batch 6100/53340, Loss: 3.7598\n",
      "Epoch 1, Batch 6200/53340, Loss: 3.6650\n",
      "Epoch 1, Batch 6300/53340, Loss: 3.4928\n",
      "Epoch 1, Batch 6400/53340, Loss: 3.2959\n",
      "Epoch 1, Batch 6500/53340, Loss: 3.0439\n",
      "Epoch 1, Batch 6600/53340, Loss: 2.7723\n",
      "Epoch 1, Batch 6700/53340, Loss: 2.4725\n",
      "Epoch 1, Batch 6800/53340, Loss: 3.1889\n",
      "Epoch 1, Batch 6900/53340, Loss: 2.3618\n",
      "Epoch 1, Batch 7000/53340, Loss: 3.5184\n",
      "Epoch 1, Batch 7100/53340, Loss: 3.2582\n",
      "Epoch 1, Batch 7200/53340, Loss: 2.8889\n",
      "Epoch 1, Batch 7300/53340, Loss: 2.9940\n",
      "Epoch 1, Batch 7400/53340, Loss: 2.5099\n",
      "Epoch 1, Batch 7500/53340, Loss: 2.0434\n",
      "Epoch 1, Batch 7600/53340, Loss: 2.6485\n",
      "Epoch 1, Batch 7700/53340, Loss: 3.3358\n",
      "Epoch 1, Batch 7800/53340, Loss: 3.4028\n",
      "Epoch 1, Batch 7900/53340, Loss: 2.5161\n",
      "Epoch 1, Batch 8000/53340, Loss: 2.8684\n",
      "Epoch 1, Batch 8100/53340, Loss: 1.5978\n",
      "Epoch 1, Batch 8200/53340, Loss: 3.7280\n",
      "Epoch 1, Batch 8300/53340, Loss: 2.5033\n",
      "Epoch 1, Batch 8400/53340, Loss: 3.5831\n",
      "Epoch 1, Batch 8500/53340, Loss: 2.9682\n",
      "Epoch 1, Batch 8600/53340, Loss: 2.5600\n",
      "Epoch 1, Batch 8700/53340, Loss: 2.6129\n",
      "Epoch 1, Batch 8800/53340, Loss: 2.6661\n",
      "Epoch 1, Batch 8900/53340, Loss: 2.0533\n",
      "Epoch 1, Batch 9000/53340, Loss: 3.3688\n",
      "Epoch 1, Batch 9100/53340, Loss: 3.2914\n",
      "Epoch 1, Batch 9200/53340, Loss: 2.8358\n",
      "Epoch 1, Batch 9300/53340, Loss: 1.9570\n",
      "Epoch 1, Batch 9400/53340, Loss: 7.5090\n",
      "Epoch 1, Batch 9500/53340, Loss: 2.3684\n",
      "Epoch 1, Batch 9600/53340, Loss: 2.1950\n",
      "Epoch 1, Batch 9700/53340, Loss: 3.1972\n",
      "Epoch 1, Batch 9800/53340, Loss: 1.9951\n",
      "Epoch 1, Batch 9900/53340, Loss: 3.3614\n",
      "Epoch 1, Batch 10000/53340, Loss: 1.9013\n",
      "Epoch 1, Batch 10100/53340, Loss: 2.8486\n",
      "Epoch 1, Batch 10200/53340, Loss: 3.5520\n",
      "Epoch 1, Batch 10300/53340, Loss: 1.5622\n",
      "Epoch 1, Batch 10400/53340, Loss: 3.0192\n",
      "Epoch 1, Batch 10500/53340, Loss: 2.4184\n",
      "Epoch 1, Batch 10600/53340, Loss: 1.8434\n",
      "Epoch 1, Batch 10700/53340, Loss: 2.5418\n",
      "Epoch 1, Batch 10800/53340, Loss: 2.4376\n",
      "Epoch 1, Batch 10900/53340, Loss: 2.1915\n",
      "Epoch 1, Batch 11000/53340, Loss: 2.4614\n",
      "Epoch 1, Batch 11100/53340, Loss: 1.9881\n",
      "Epoch 1, Batch 11200/53340, Loss: 2.1910\n",
      "Epoch 1, Batch 11300/53340, Loss: 1.7176\n",
      "Epoch 1, Batch 11400/53340, Loss: 2.2409\n",
      "Epoch 1, Batch 11500/53340, Loss: 3.3576\n",
      "Epoch 1, Batch 11600/53340, Loss: 2.5046\n",
      "Epoch 1, Batch 11700/53340, Loss: 2.9327\n",
      "Epoch 1, Batch 11800/53340, Loss: 2.1109\n",
      "Epoch 1, Batch 11900/53340, Loss: 2.1795\n",
      "Epoch 1, Batch 12000/53340, Loss: 1.9194\n",
      "Epoch 1, Batch 12100/53340, Loss: 2.7446\n",
      "Epoch 1, Batch 12200/53340, Loss: 3.3704\n",
      "Epoch 1, Batch 12300/53340, Loss: 2.2219\n",
      "Epoch 1, Batch 12400/53340, Loss: 2.9785\n",
      "Epoch 1, Batch 12500/53340, Loss: 1.8463\n",
      "Epoch 1, Batch 12600/53340, Loss: 2.3419\n",
      "Epoch 1, Batch 12700/53340, Loss: 2.5180\n",
      "Epoch 1, Batch 12800/53340, Loss: 2.3332\n",
      "Epoch 1, Batch 12900/53340, Loss: 2.3626\n",
      "Epoch 1, Batch 13000/53340, Loss: 1.8467\n",
      "Epoch 1, Batch 13100/53340, Loss: 2.4086\n",
      "Epoch 1, Batch 13200/53340, Loss: 2.2287\n",
      "Epoch 1, Batch 13300/53340, Loss: 2.3439\n",
      "Epoch 1, Batch 13400/53340, Loss: 2.1110\n",
      "Epoch 1, Batch 13500/53340, Loss: 2.6038\n",
      "Epoch 1, Batch 13600/53340, Loss: 2.5534\n",
      "Epoch 1, Batch 13700/53340, Loss: 2.3117\n",
      "Epoch 1, Batch 13800/53340, Loss: 1.7679\n",
      "Epoch 1, Batch 13900/53340, Loss: 2.3704\n",
      "Epoch 1, Batch 14000/53340, Loss: 2.9282\n",
      "Epoch 1, Batch 14100/53340, Loss: 2.3547\n",
      "Epoch 1, Batch 14200/53340, Loss: 2.1461\n",
      "Epoch 1, Batch 14300/53340, Loss: 1.9789\n",
      "Epoch 1, Batch 14400/53340, Loss: 2.4806\n",
      "Epoch 1, Batch 14500/53340, Loss: 4.1608\n",
      "Epoch 1, Batch 14600/53340, Loss: 1.9275\n",
      "Epoch 1, Batch 14700/53340, Loss: 1.8565\n",
      "Epoch 1, Batch 14800/53340, Loss: 1.5731\n",
      "Epoch 1, Batch 14900/53340, Loss: 1.4231\n",
      "Epoch 1, Batch 15000/53340, Loss: 2.2309\n",
      "Epoch 1, Batch 15100/53340, Loss: 1.9392\n",
      "Epoch 1, Batch 15200/53340, Loss: 1.6223\n",
      "Epoch 1, Batch 15300/53340, Loss: 2.1445\n",
      "Epoch 1, Batch 15400/53340, Loss: 1.8203\n",
      "Epoch 1, Batch 15500/53340, Loss: 1.5999\n",
      "Epoch 1, Batch 15600/53340, Loss: 1.9423\n",
      "Epoch 1, Batch 15700/53340, Loss: 1.9801\n",
      "Epoch 1, Batch 15800/53340, Loss: 1.8540\n",
      "Epoch 1, Batch 15900/53340, Loss: 2.1502\n",
      "Epoch 1, Batch 16000/53340, Loss: 1.6012\n",
      "Epoch 1, Batch 16100/53340, Loss: 2.5606\n",
      "Epoch 1, Batch 16200/53340, Loss: 2.7626\n",
      "Epoch 1, Batch 16300/53340, Loss: 1.5281\n",
      "Epoch 1, Batch 16400/53340, Loss: 2.2525\n",
      "Epoch 1, Batch 16500/53340, Loss: 1.9072\n",
      "Epoch 1, Batch 16600/53340, Loss: 1.9659\n",
      "Epoch 1, Batch 16700/53340, Loss: 1.8132\n",
      "Epoch 1, Batch 16800/53340, Loss: 1.2150\n",
      "Epoch 1, Batch 16900/53340, Loss: 1.9756\n",
      "Epoch 1, Batch 17000/53340, Loss: 1.5338\n",
      "Epoch 1, Batch 17100/53340, Loss: 1.7026\n",
      "Epoch 1, Batch 17200/53340, Loss: 1.6955\n",
      "Epoch 1, Batch 17300/53340, Loss: 1.4566\n",
      "Epoch 1, Batch 17400/53340, Loss: 1.5143\n",
      "Epoch 1, Batch 17500/53340, Loss: 1.7104\n",
      "Epoch 1, Batch 17600/53340, Loss: 2.0118\n",
      "Epoch 1, Batch 17700/53340, Loss: 1.7403\n",
      "Epoch 1, Batch 17800/53340, Loss: 1.5222\n",
      "Epoch 1, Batch 17900/53340, Loss: 1.7259\n",
      "Epoch 1, Batch 18000/53340, Loss: 1.6586\n",
      "Epoch 1, Batch 18100/53340, Loss: 2.1978\n",
      "Epoch 1, Batch 18200/53340, Loss: 2.0729\n",
      "Epoch 1, Batch 18300/53340, Loss: 1.4670\n",
      "Epoch 1, Batch 18400/53340, Loss: 1.6812\n",
      "Epoch 1, Batch 18500/53340, Loss: 1.7470\n",
      "Epoch 1, Batch 18600/53340, Loss: 1.3144\n",
      "Epoch 1, Batch 18700/53340, Loss: 1.7954\n",
      "Epoch 1, Batch 18800/53340, Loss: 1.9432\n",
      "Epoch 1, Batch 18900/53340, Loss: 1.6769\n",
      "Epoch 1, Batch 19000/53340, Loss: 2.3034\n",
      "Epoch 1, Batch 19100/53340, Loss: 1.7662\n",
      "Epoch 1, Batch 19200/53340, Loss: 1.9941\n",
      "Epoch 1, Batch 19300/53340, Loss: 2.0432\n",
      "Epoch 1, Batch 19400/53340, Loss: 1.9673\n",
      "Epoch 1, Batch 19500/53340, Loss: 1.6614\n",
      "Epoch 1, Batch 19600/53340, Loss: 1.8780\n",
      "Epoch 1, Batch 19700/53340, Loss: 1.8085\n",
      "Epoch 1, Batch 19800/53340, Loss: 1.6913\n",
      "Epoch 1, Batch 19900/53340, Loss: 1.4814\n",
      "Epoch 1, Batch 20000/53340, Loss: 2.9361\n",
      "Epoch 1, Batch 20100/53340, Loss: 1.3893\n",
      "Epoch 1, Batch 20200/53340, Loss: 1.8728\n",
      "Epoch 1, Batch 20300/53340, Loss: 1.6525\n",
      "Epoch 1, Batch 20400/53340, Loss: 2.6819\n",
      "Epoch 1, Batch 20500/53340, Loss: 2.6605\n",
      "Epoch 1, Batch 20600/53340, Loss: 2.0742\n",
      "Epoch 1, Batch 20700/53340, Loss: 2.0216\n",
      "Epoch 1, Batch 20800/53340, Loss: 1.7220\n",
      "Epoch 1, Batch 20900/53340, Loss: 2.1946\n",
      "Epoch 1, Batch 21000/53340, Loss: 1.6267\n",
      "Epoch 1, Batch 21100/53340, Loss: 1.9838\n",
      "Epoch 1, Batch 21200/53340, Loss: 1.8262\n",
      "Epoch 1, Batch 21300/53340, Loss: 2.3996\n",
      "Epoch 1, Batch 21400/53340, Loss: 2.1293\n",
      "Epoch 1, Batch 21500/53340, Loss: 2.2002\n",
      "Epoch 1, Batch 21600/53340, Loss: 1.8348\n",
      "Epoch 1, Batch 21700/53340, Loss: 2.1255\n",
      "Epoch 1, Batch 21800/53340, Loss: 2.3813\n",
      "Epoch 1, Batch 21900/53340, Loss: 1.2002\n",
      "Epoch 1, Batch 22000/53340, Loss: 1.8246\n",
      "Epoch 1, Batch 22100/53340, Loss: 1.6243\n",
      "Epoch 1, Batch 22200/53340, Loss: 1.6902\n",
      "Epoch 1, Batch 22300/53340, Loss: 3.7485\n",
      "Epoch 1, Batch 22400/53340, Loss: 1.3743\n",
      "Epoch 1, Batch 22500/53340, Loss: 2.3448\n",
      "Epoch 1, Batch 22600/53340, Loss: 2.2031\n",
      "Epoch 1, Batch 22700/53340, Loss: 1.3697\n",
      "Epoch 1, Batch 22800/53340, Loss: 2.2222\n",
      "Epoch 1, Batch 22900/53340, Loss: 1.8929\n",
      "Epoch 1, Batch 23000/53340, Loss: 1.6989\n",
      "Epoch 1, Batch 23100/53340, Loss: 1.2805\n",
      "Epoch 1, Batch 23200/53340, Loss: 1.5226\n",
      "Epoch 1, Batch 23300/53340, Loss: 2.4561\n",
      "Epoch 1, Batch 23400/53340, Loss: 1.5788\n",
      "Epoch 1, Batch 23500/53340, Loss: 1.5478\n",
      "Epoch 1, Batch 23600/53340, Loss: 4.2493\n",
      "Epoch 1, Batch 23700/53340, Loss: 1.6800\n",
      "Epoch 1, Batch 23800/53340, Loss: 1.7837\n",
      "Epoch 1, Batch 23900/53340, Loss: 2.1440\n",
      "Epoch 1, Batch 24000/53340, Loss: 1.8512\n",
      "Epoch 1, Batch 24100/53340, Loss: 3.2348\n",
      "Epoch 1, Batch 24200/53340, Loss: 1.3173\n",
      "Epoch 1, Batch 24300/53340, Loss: 2.4973\n",
      "Epoch 1, Batch 24400/53340, Loss: 2.0800\n",
      "Epoch 1, Batch 24500/53340, Loss: 1.9797\n",
      "Epoch 1, Batch 24600/53340, Loss: 1.8094\n",
      "Epoch 1, Batch 24700/53340, Loss: 1.5953\n",
      "Epoch 1, Batch 24800/53340, Loss: 1.3076\n",
      "Epoch 1, Batch 24900/53340, Loss: 1.6911\n",
      "Epoch 1, Batch 25000/53340, Loss: 1.4097\n",
      "Epoch 1, Batch 25100/53340, Loss: 1.7097\n",
      "Epoch 1, Batch 25200/53340, Loss: 1.6366\n",
      "Epoch 1, Batch 25300/53340, Loss: 2.6169\n",
      "Epoch 1, Batch 25400/53340, Loss: 2.3121\n",
      "Epoch 1, Batch 25500/53340, Loss: 2.2424\n",
      "Epoch 1, Batch 25600/53340, Loss: 1.7222\n",
      "Epoch 1, Batch 25700/53340, Loss: 1.4006\n",
      "Epoch 1, Batch 25800/53340, Loss: 1.5978\n",
      "Epoch 1, Batch 25900/53340, Loss: 1.5300\n",
      "Epoch 1, Batch 26000/53340, Loss: 2.2963\n",
      "Epoch 1, Batch 26100/53340, Loss: 1.4912\n",
      "Epoch 1, Batch 26200/53340, Loss: 1.5045\n",
      "Epoch 1, Batch 26300/53340, Loss: 3.6112\n",
      "Epoch 1, Batch 26400/53340, Loss: 1.7785\n",
      "Epoch 1, Batch 26500/53340, Loss: 1.6039\n",
      "Epoch 1, Batch 26600/53340, Loss: 1.6856\n",
      "Epoch 1, Batch 26700/53340, Loss: 1.9854\n",
      "Epoch 1, Batch 26800/53340, Loss: 1.5048\n",
      "Epoch 1, Batch 26900/53340, Loss: 3.2591\n",
      "Epoch 1, Batch 27000/53340, Loss: 2.1231\n",
      "Epoch 1, Batch 27100/53340, Loss: 1.5642\n",
      "Epoch 1, Batch 27200/53340, Loss: 1.3210\n",
      "Epoch 1, Batch 27300/53340, Loss: 1.5101\n",
      "Epoch 1, Batch 27400/53340, Loss: 1.3460\n",
      "Epoch 1, Batch 27500/53340, Loss: 1.6858\n",
      "Epoch 1, Batch 27600/53340, Loss: 2.4712\n",
      "Epoch 1, Batch 27700/53340, Loss: 2.9357\n",
      "Epoch 1, Batch 27800/53340, Loss: 1.5562\n",
      "Epoch 1, Batch 27900/53340, Loss: 1.7600\n",
      "Epoch 1, Batch 28000/53340, Loss: 1.3733\n",
      "Epoch 1, Batch 28100/53340, Loss: 1.6633\n",
      "Epoch 1, Batch 28200/53340, Loss: 1.7401\n",
      "Epoch 1, Batch 28300/53340, Loss: 1.3826\n",
      "Epoch 1, Batch 28400/53340, Loss: 2.1323\n",
      "Epoch 1, Batch 28500/53340, Loss: 1.4951\n",
      "Epoch 1, Batch 28600/53340, Loss: 1.8642\n",
      "Epoch 1, Batch 28700/53340, Loss: 1.6650\n",
      "Epoch 1, Batch 28800/53340, Loss: 1.7904\n",
      "Epoch 1, Batch 28900/53340, Loss: 3.3170\n",
      "Epoch 1, Batch 29000/53340, Loss: 1.4327\n",
      "Epoch 1, Batch 29100/53340, Loss: 1.4884\n",
      "Epoch 1, Batch 29200/53340, Loss: 1.5486\n",
      "Epoch 1, Batch 29300/53340, Loss: 1.8555\n",
      "Epoch 1, Batch 29400/53340, Loss: 1.1143\n",
      "Epoch 1, Batch 29500/53340, Loss: 1.8646\n",
      "Epoch 1, Batch 29600/53340, Loss: 1.3993\n",
      "Epoch 1, Batch 29700/53340, Loss: 1.2713\n",
      "Epoch 1, Batch 29800/53340, Loss: 1.5962\n",
      "Epoch 1, Batch 29900/53340, Loss: 1.5541\n",
      "Epoch 1, Batch 30000/53340, Loss: 2.0489\n",
      "Epoch 1, Batch 30100/53340, Loss: 1.4021\n",
      "Epoch 1, Batch 30200/53340, Loss: 1.6582\n",
      "Epoch 1, Batch 30300/53340, Loss: 1.5561\n",
      "Epoch 1, Batch 30400/53340, Loss: 1.6968\n",
      "Epoch 1, Batch 30500/53340, Loss: 2.0443\n",
      "Epoch 1, Batch 30600/53340, Loss: 1.9227\n",
      "Epoch 1, Batch 30700/53340, Loss: 1.5536\n",
      "Epoch 1, Batch 30800/53340, Loss: 1.4696\n",
      "Epoch 1, Batch 30900/53340, Loss: 1.8392\n",
      "Epoch 1, Batch 31000/53340, Loss: 1.8120\n",
      "Epoch 1, Batch 31100/53340, Loss: 1.0095\n",
      "Epoch 1, Batch 31200/53340, Loss: 1.6050\n",
      "Epoch 1, Batch 31300/53340, Loss: 1.6070\n",
      "Epoch 1, Batch 31400/53340, Loss: 1.7700\n",
      "Epoch 1, Batch 31500/53340, Loss: 1.8905\n",
      "Epoch 1, Batch 31600/53340, Loss: 1.6452\n",
      "Epoch 1, Batch 31700/53340, Loss: 1.4365\n",
      "Epoch 1, Batch 31800/53340, Loss: 1.6921\n",
      "Epoch 1, Batch 31900/53340, Loss: 1.4347\n",
      "Epoch 1, Batch 32000/53340, Loss: 1.5096\n",
      "Epoch 1, Batch 32100/53340, Loss: 2.5140\n",
      "Epoch 1, Batch 32200/53340, Loss: 1.7849\n",
      "Epoch 1, Batch 32300/53340, Loss: 1.8456\n",
      "Epoch 1, Batch 32400/53340, Loss: 1.9861\n",
      "Epoch 1, Batch 32500/53340, Loss: 1.7493\n",
      "Epoch 1, Batch 32600/53340, Loss: 1.3517\n",
      "Epoch 1, Batch 32700/53340, Loss: 1.2664\n",
      "Epoch 1, Batch 32800/53340, Loss: 1.7032\n",
      "Epoch 1, Batch 32900/53340, Loss: 1.4040\n",
      "Epoch 1, Batch 33000/53340, Loss: 1.1838\n",
      "Epoch 1, Batch 33100/53340, Loss: 1.5825\n",
      "Epoch 1, Batch 33200/53340, Loss: 1.6445\n",
      "Epoch 1, Batch 33300/53340, Loss: 2.0656\n",
      "Epoch 1, Batch 33400/53340, Loss: 1.7541\n",
      "Epoch 1, Batch 33500/53340, Loss: 1.6968\n",
      "Epoch 1, Batch 33600/53340, Loss: 1.8534\n",
      "Epoch 1, Batch 33700/53340, Loss: 1.5901\n",
      "Epoch 1, Batch 33800/53340, Loss: 1.4607\n",
      "Epoch 1, Batch 33900/53340, Loss: 1.9558\n",
      "Epoch 1, Batch 34000/53340, Loss: 1.1505\n",
      "Epoch 1, Batch 34100/53340, Loss: 1.9246\n",
      "Epoch 1, Batch 34200/53340, Loss: 1.9177\n",
      "Epoch 1, Batch 34300/53340, Loss: 4.6660\n",
      "Epoch 1, Batch 34400/53340, Loss: 1.6769\n",
      "Epoch 1, Batch 34500/53340, Loss: 1.1575\n",
      "Epoch 1, Batch 34600/53340, Loss: 1.8052\n",
      "Epoch 1, Batch 34700/53340, Loss: 1.6932\n",
      "Epoch 1, Batch 34800/53340, Loss: 1.7201\n",
      "Epoch 1, Batch 34900/53340, Loss: 1.8768\n",
      "Epoch 1, Batch 35000/53340, Loss: 1.4693\n",
      "Epoch 1, Batch 35100/53340, Loss: 0.9930\n",
      "Epoch 1, Batch 35200/53340, Loss: 1.0906\n",
      "Epoch 1, Batch 35300/53340, Loss: 1.5054\n",
      "Epoch 1, Batch 35400/53340, Loss: 2.0689\n",
      "Epoch 1, Batch 35500/53340, Loss: 2.7213\n",
      "Epoch 1, Batch 35600/53340, Loss: 1.4220\n",
      "Epoch 1, Batch 35700/53340, Loss: 1.3477\n",
      "Epoch 1, Batch 35800/53340, Loss: 1.5116\n",
      "Epoch 1, Batch 35900/53340, Loss: 1.7164\n",
      "Epoch 1, Batch 36000/53340, Loss: 1.4633\n",
      "Epoch 1, Batch 36100/53340, Loss: 1.8621\n",
      "Epoch 1, Batch 36200/53340, Loss: 1.7108\n",
      "Epoch 1, Batch 36300/53340, Loss: 1.2374\n",
      "Epoch 1, Batch 36400/53340, Loss: 2.3885\n",
      "Epoch 1, Batch 36500/53340, Loss: 1.2801\n",
      "Epoch 1, Batch 36600/53340, Loss: 1.3648\n",
      "Epoch 1, Batch 36700/53340, Loss: 1.9757\n",
      "Epoch 1, Batch 36800/53340, Loss: 1.5758\n",
      "Epoch 1, Batch 36900/53340, Loss: 1.0236\n",
      "Epoch 1, Batch 37000/53340, Loss: 3.2254\n",
      "Epoch 1, Batch 37100/53340, Loss: 1.3385\n",
      "Epoch 1, Batch 37200/53340, Loss: 1.5921\n",
      "Epoch 1, Batch 37300/53340, Loss: 1.8073\n",
      "Epoch 1, Batch 37400/53340, Loss: 2.0927\n",
      "Epoch 1, Batch 37500/53340, Loss: 1.3332\n",
      "Epoch 1, Batch 37600/53340, Loss: 1.0810\n",
      "Epoch 1, Batch 37700/53340, Loss: 1.4153\n",
      "Epoch 1, Batch 37800/53340, Loss: 1.5168\n",
      "Epoch 1, Batch 37900/53340, Loss: 2.0166\n",
      "Epoch 1, Batch 38000/53340, Loss: 1.7374\n",
      "Epoch 1, Batch 38100/53340, Loss: 1.1728\n",
      "Epoch 1, Batch 38200/53340, Loss: 1.4645\n",
      "Epoch 1, Batch 38300/53340, Loss: 1.2912\n",
      "Epoch 1, Batch 38400/53340, Loss: 1.2904\n",
      "Epoch 1, Batch 38500/53340, Loss: 1.8971\n",
      "Epoch 1, Batch 38600/53340, Loss: 1.7891\n",
      "Epoch 1, Batch 38700/53340, Loss: 1.3896\n",
      "Epoch 1, Batch 38800/53340, Loss: 1.7006\n",
      "Epoch 1, Batch 38900/53340, Loss: 1.3442\n",
      "Epoch 1, Batch 39000/53340, Loss: 1.7365\n",
      "Epoch 1, Batch 39100/53340, Loss: 1.1085\n",
      "Epoch 1, Batch 39200/53340, Loss: 1.2206\n",
      "Epoch 1, Batch 39300/53340, Loss: 1.5561\n",
      "Epoch 1, Batch 39400/53340, Loss: 1.4247\n",
      "Epoch 1, Batch 39500/53340, Loss: 1.2964\n",
      "Epoch 1, Batch 39600/53340, Loss: 1.9427\n",
      "Epoch 1, Batch 39700/53340, Loss: 1.3562\n",
      "Epoch 1, Batch 39800/53340, Loss: 1.4736\n",
      "Epoch 1, Batch 39900/53340, Loss: 1.6765\n",
      "Epoch 1, Batch 40000/53340, Loss: 2.2555\n",
      "Epoch 1, Batch 40100/53340, Loss: 2.0230\n",
      "Epoch 1, Batch 40200/53340, Loss: 1.5764\n",
      "Epoch 1, Batch 40300/53340, Loss: 1.6612\n",
      "Epoch 1, Batch 40400/53340, Loss: 1.7228\n",
      "Epoch 1, Batch 40500/53340, Loss: 1.8458\n",
      "Epoch 1, Batch 40600/53340, Loss: 2.0112\n",
      "Epoch 1, Batch 40700/53340, Loss: 0.8936\n",
      "Epoch 1, Batch 40800/53340, Loss: 1.4314\n",
      "Epoch 1, Batch 40900/53340, Loss: 1.2106\n",
      "Epoch 1, Batch 41000/53340, Loss: 1.9232\n",
      "Epoch 1, Batch 41100/53340, Loss: 1.5868\n",
      "Epoch 1, Batch 41200/53340, Loss: 1.3761\n",
      "Epoch 1, Batch 41300/53340, Loss: 0.9142\n",
      "Epoch 1, Batch 41400/53340, Loss: 1.3316\n",
      "Epoch 1, Batch 41500/53340, Loss: 0.9765\n",
      "Epoch 1, Batch 41600/53340, Loss: 1.3904\n",
      "Epoch 1, Batch 41700/53340, Loss: 1.8646\n",
      "Epoch 1, Batch 41800/53340, Loss: 1.5529\n",
      "Epoch 1, Batch 41900/53340, Loss: 1.5321\n",
      "Epoch 1, Batch 42000/53340, Loss: 1.4559\n",
      "Epoch 1, Batch 42100/53340, Loss: 1.3277\n",
      "Epoch 1, Batch 42200/53340, Loss: 1.5590\n",
      "Epoch 1, Batch 42300/53340, Loss: 2.0313\n",
      "Epoch 1, Batch 42400/53340, Loss: 1.1373\n",
      "Epoch 1, Batch 42500/53340, Loss: 1.5787\n",
      "Epoch 1, Batch 42600/53340, Loss: 2.2486\n",
      "Epoch 1, Batch 42700/53340, Loss: 1.1809\n",
      "Epoch 1, Batch 42800/53340, Loss: 1.8084\n",
      "Epoch 1, Batch 42900/53340, Loss: 1.6413\n",
      "Epoch 1, Batch 43000/53340, Loss: 2.0266\n",
      "Epoch 1, Batch 43100/53340, Loss: 1.2791\n",
      "Epoch 1, Batch 43200/53340, Loss: 2.0420\n",
      "Epoch 1, Batch 43300/53340, Loss: 1.8768\n",
      "Epoch 1, Batch 43400/53340, Loss: 1.6585\n",
      "Epoch 1, Batch 43500/53340, Loss: 1.7128\n",
      "Epoch 1, Batch 43600/53340, Loss: 0.9633\n",
      "Epoch 1, Batch 43700/53340, Loss: 1.4416\n",
      "Epoch 1, Batch 43800/53340, Loss: 1.4927\n",
      "Epoch 1, Batch 43900/53340, Loss: 1.8619\n",
      "Epoch 1, Batch 44000/53340, Loss: 1.4171\n",
      "Epoch 1, Batch 44100/53340, Loss: 1.1857\n",
      "Epoch 1, Batch 44200/53340, Loss: 1.7115\n",
      "Epoch 1, Batch 44300/53340, Loss: 1.5385\n",
      "Epoch 1, Batch 44400/53340, Loss: 1.6158\n",
      "Epoch 1, Batch 44500/53340, Loss: 1.4905\n",
      "Epoch 1, Batch 44600/53340, Loss: 3.1590\n",
      "Epoch 1, Batch 44700/53340, Loss: 1.3850\n",
      "Epoch 1, Batch 44800/53340, Loss: 1.5885\n",
      "Epoch 1, Batch 44900/53340, Loss: 1.0373\n",
      "Epoch 1, Batch 45000/53340, Loss: 1.2123\n",
      "Epoch 1, Batch 45100/53340, Loss: 1.9656\n",
      "Epoch 1, Batch 45200/53340, Loss: 3.0344\n",
      "Epoch 1, Batch 45300/53340, Loss: 1.4456\n",
      "Epoch 1, Batch 45400/53340, Loss: 1.5253\n",
      "Epoch 1, Batch 45500/53340, Loss: 1.2704\n",
      "Epoch 1, Batch 45600/53340, Loss: 1.2214\n",
      "Epoch 1, Batch 45700/53340, Loss: 1.3719\n",
      "Epoch 1, Batch 45800/53340, Loss: 1.3684\n",
      "Epoch 1, Batch 45900/53340, Loss: 1.4028\n",
      "Epoch 1, Batch 46000/53340, Loss: 1.8548\n",
      "Epoch 1, Batch 46100/53340, Loss: 1.2828\n",
      "Epoch 1, Batch 46200/53340, Loss: 1.0022\n",
      "Epoch 1, Batch 46300/53340, Loss: 1.5620\n",
      "Epoch 1, Batch 46400/53340, Loss: 1.5583\n",
      "Epoch 1, Batch 46500/53340, Loss: 1.4226\n",
      "Epoch 1, Batch 46600/53340, Loss: 1.2191\n",
      "Epoch 1, Batch 46700/53340, Loss: 1.5572\n",
      "Epoch 1, Batch 46800/53340, Loss: 1.1499\n",
      "Epoch 1, Batch 46900/53340, Loss: 1.4148\n",
      "Epoch 1, Batch 47000/53340, Loss: 1.1659\n",
      "Epoch 1, Batch 47100/53340, Loss: 1.5318\n",
      "Epoch 1, Batch 47200/53340, Loss: 1.8829\n",
      "Epoch 1, Batch 47300/53340, Loss: 2.0526\n",
      "Epoch 1, Batch 47400/53340, Loss: 1.4909\n",
      "Epoch 1, Batch 47500/53340, Loss: 1.2377\n",
      "Epoch 1, Batch 47600/53340, Loss: 1.5089\n",
      "Epoch 1, Batch 47700/53340, Loss: 1.3391\n",
      "Epoch 1, Batch 47800/53340, Loss: 1.7334\n",
      "Epoch 1, Batch 47900/53340, Loss: 1.4862\n",
      "Epoch 1, Batch 48000/53340, Loss: 1.4277\n",
      "Epoch 1, Batch 48100/53340, Loss: 1.5132\n",
      "Epoch 1, Batch 48200/53340, Loss: 1.8059\n",
      "Epoch 1, Batch 48300/53340, Loss: 3.0183\n",
      "Epoch 1, Batch 48400/53340, Loss: 1.9666\n",
      "Epoch 1, Batch 48500/53340, Loss: 1.7481\n",
      "Epoch 1, Batch 48600/53340, Loss: 1.5818\n",
      "Epoch 1, Batch 48700/53340, Loss: 1.7309\n",
      "Epoch 1, Batch 48800/53340, Loss: 1.4039\n",
      "Epoch 1, Batch 48900/53340, Loss: 1.5344\n",
      "Epoch 1, Batch 49000/53340, Loss: 1.3122\n",
      "Epoch 1, Batch 49100/53340, Loss: 1.5404\n",
      "Epoch 1, Batch 49200/53340, Loss: 1.4910\n",
      "Epoch 1, Batch 49300/53340, Loss: 2.5961\n",
      "Epoch 1, Batch 49400/53340, Loss: 1.0522\n",
      "Epoch 1, Batch 49500/53340, Loss: 1.3459\n",
      "Epoch 1, Batch 49600/53340, Loss: 1.6656\n",
      "Epoch 1, Batch 49700/53340, Loss: 2.1886\n",
      "Epoch 1, Batch 49800/53340, Loss: 1.2164\n",
      "Epoch 1, Batch 49900/53340, Loss: 1.7704\n",
      "Epoch 1, Batch 50000/53340, Loss: 1.7709\n",
      "Epoch 1, Batch 50100/53340, Loss: 1.6228\n",
      "Epoch 1, Batch 50200/53340, Loss: 0.9777\n",
      "Epoch 1, Batch 50300/53340, Loss: 1.6187\n",
      "Epoch 1, Batch 50400/53340, Loss: 1.3601\n",
      "Epoch 1, Batch 50500/53340, Loss: 1.7410\n",
      "Epoch 1, Batch 50600/53340, Loss: 1.3556\n",
      "Epoch 1, Batch 50700/53340, Loss: 1.9757\n",
      "Epoch 1, Batch 50800/53340, Loss: 1.6350\n",
      "Epoch 1, Batch 50900/53340, Loss: 1.6160\n",
      "Epoch 1, Batch 51000/53340, Loss: 1.7144\n",
      "Epoch 1, Batch 51100/53340, Loss: 1.9963\n",
      "Epoch 1, Batch 51200/53340, Loss: 1.0562\n",
      "Epoch 1, Batch 51300/53340, Loss: 1.5414\n",
      "Epoch 1, Batch 51400/53340, Loss: 1.6032\n",
      "Epoch 1, Batch 51500/53340, Loss: 1.7501\n",
      "Epoch 1, Batch 51600/53340, Loss: 1.9808\n",
      "Epoch 1, Batch 51700/53340, Loss: 1.3789\n",
      "Epoch 1, Batch 51800/53340, Loss: 1.5317\n",
      "Epoch 1, Batch 51900/53340, Loss: 1.7381\n",
      "Epoch 1, Batch 52000/53340, Loss: 0.9237\n",
      "Epoch 1, Batch 52100/53340, Loss: 1.3191\n",
      "Epoch 1, Batch 52200/53340, Loss: 0.9491\n",
      "Epoch 1, Batch 52300/53340, Loss: 1.3598\n",
      "Epoch 1, Batch 52400/53340, Loss: 1.0109\n",
      "Epoch 1, Batch 52500/53340, Loss: 1.5188\n",
      "Epoch 1, Batch 52600/53340, Loss: 1.1849\n",
      "Epoch 1, Batch 52700/53340, Loss: 1.7354\n",
      "Epoch 1, Batch 52800/53340, Loss: 1.3694\n",
      "Epoch 1, Batch 52900/53340, Loss: 1.5386\n",
      "Epoch 1, Batch 53000/53340, Loss: 1.4391\n",
      "Epoch 1, Batch 53100/53340, Loss: 1.4079\n",
      "Epoch 1, Batch 53200/53340, Loss: 1.6211\n",
      "Epoch 1, Batch 53300/53340, Loss: 1.6224\n",
      "\n",
      "Average training loss: 2.0976\n",
      "Learning rate: 0.000100\n",
      "\n",
      "Evaluating on test set...\n",
      "Evaluating on 5384 image pairs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/semantic_correspondence/helper_functions.py:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated 100/5384 pairs...\n",
      "Evaluated 200/5384 pairs...\n",
      "Evaluated 300/5384 pairs...\n",
      "Evaluated 400/5384 pairs...\n",
      "Evaluated 500/5384 pairs...\n",
      "Evaluated 600/5384 pairs...\n",
      "Evaluated 700/5384 pairs...\n",
      "Evaluated 800/5384 pairs...\n",
      "Evaluated 900/5384 pairs...\n",
      "Evaluated 1000/5384 pairs...\n",
      "Evaluated 1100/5384 pairs...\n",
      "Evaluated 1200/5384 pairs...\n",
      "Evaluated 1300/5384 pairs...\n",
      "Evaluated 1400/5384 pairs...\n",
      "Evaluated 1500/5384 pairs...\n",
      "Evaluated 1600/5384 pairs...\n",
      "Evaluated 1700/5384 pairs...\n",
      "Evaluated 1800/5384 pairs...\n",
      "Evaluated 1900/5384 pairs...\n",
      "Evaluated 2000/5384 pairs...\n",
      "Evaluated 2100/5384 pairs...\n",
      "Evaluated 2200/5384 pairs...\n",
      "Evaluated 2300/5384 pairs...\n",
      "Evaluated 2400/5384 pairs...\n",
      "Evaluated 2500/5384 pairs...\n",
      "Evaluated 2600/5384 pairs...\n",
      "Evaluated 2700/5384 pairs...\n",
      "Evaluated 2800/5384 pairs...\n",
      "Evaluated 2900/5384 pairs...\n",
      "Evaluated 3000/5384 pairs...\n",
      "Evaluated 3100/5384 pairs...\n",
      "Evaluated 3200/5384 pairs...\n",
      "Evaluated 3300/5384 pairs...\n",
      "Evaluated 3400/5384 pairs...\n",
      "Evaluated 3500/5384 pairs...\n",
      "Evaluated 3600/5384 pairs...\n",
      "Evaluated 3700/5384 pairs...\n",
      "Evaluated 3800/5384 pairs...\n",
      "Evaluated 3900/5384 pairs...\n",
      "Evaluated 4000/5384 pairs...\n",
      "Evaluated 4100/5384 pairs...\n",
      "Evaluated 4200/5384 pairs...\n",
      "Evaluated 4300/5384 pairs...\n",
      "Evaluated 4400/5384 pairs...\n",
      "Evaluated 4500/5384 pairs...\n",
      "Evaluated 4600/5384 pairs...\n",
      "Evaluated 4700/5384 pairs...\n",
      "Evaluated 4800/5384 pairs...\n",
      "Evaluated 4900/5384 pairs...\n",
      "Evaluated 5000/5384 pairs...\n",
      "Evaluated 5100/5384 pairs...\n",
      "Evaluated 5200/5384 pairs...\n",
      "Evaluated 5300/5384 pairs...\n",
      "Val Results:\n",
      "  PCK@0.05: 16.32%\n",
      "  PCK@0.10: 26.20%\n",
      "  PCK@0.20: 39.63%\n",
      "✓ Checkpoint saved: results_colab/SAM/lr_0.0001_t_5_blocks_2_20260115_175841/epoch_1.pth\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETED\n",
      "============================================================\n",
      "Results saved to: results_colab/SAM/lr_0.0001_t_5_blocks_2_20260115_175841\n",
      "✓ Metadata saved: results_colab/SAM/lr_0.0001_t_5_blocks_2_20260115_175841/metadata.json\n",
      "\n",
      "✓ Successfully copied results to Google Drive: /content/drive/MyDrive/Colab_dinov3_finetuning_temp_validation_results_prova/lr_0.0001_t_5_blocks_2_20260115_175841\n"
     ]
    }
   ],
   "source": [
    "import shutil # Added for copying to Google Drive\n",
    "from finetuning.simple_eval import simple_evaluate_SAM\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from datetime import datetime\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import time\n",
    "\n",
    "research_path = \"/content/semantic_correspondence/models/segment_anything\"\n",
    "if research_path not in sys.path:\n",
    "    sys.path.insert(0, research_path)\n",
    "\n",
    "# Add the parent directory of the 'segment_anything' package to sys.path\n",
    "# sys.path.append(os.path.abspath('/content/semantic_correspondence/models')) # Removed this line as it was not needed for the original error\n",
    "\n",
    "from SPair71k.devkit.SPairDataset import SPairDataset\n",
    "from helper_functions import extract_dense_features_SAM, pixel_to_patch_coord, patch_to_pixel_coord\n",
    "from finetuning.simple_eval import simple_evaluate_SAM\n",
    "from matching_strategies import find_best_match_argmax\n",
    "from pck import compute_pck_spair71k\n",
    "from models.segment_anything.segment_anything import SamPredictor, sam_model_registry # Reverted to original import path\n",
    "\n",
    "def freeze_model(model):\n",
    "    \"\"\"Freeze all model parameters\"\"\"\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "def unfreeze_last_n_blocks(model, n_blocks):\n",
    "    \"\"\"\n",
    "    Unfreeze the last n_blocks transformer blocks + final norm layer of the SAM image encoder.\n",
    "\n",
    "    Args:\n",
    "        model: SAM model\n",
    "        n_blocks: number of blocks to unfreeze (counting from the end)\n",
    "    \"\"\"\n",
    "    # Access the image encoder part of the SAM model\n",
    "    image_encoder = model.image_encoder\n",
    "\n",
    "    total_blocks = len(image_encoder.blocks)\n",
    "\n",
    "    # Unfreeze last n blocks\n",
    "    for i in range(total_blocks - n_blocks, total_blocks):\n",
    "        for param in image_encoder.blocks[i].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    # Also unfreeze the final normalization layer\n",
    "    # For SAM's ViT, this is typically model.image_encoder.neck.ln_final\n",
    "    if hasattr(image_encoder, 'neck') and hasattr(image_encoder.neck, 'ln_final'):\n",
    "        for param in image_encoder.neck.ln_final.parameters():\n",
    "            param.requires_grad = True\n",
    "        print(f\"Unfrozen last {n_blocks} blocks + final norm layer of SAM image encoder\")\n",
    "    else:\n",
    "        print(f\"Unfrozen last {n_blocks} blocks of SAM image encoder. Final norm layer not found or accessible via 'neck.ln_final'.\")\n",
    "\n",
    "\n",
    "def compute_cross_entropy_loss(src_features, tgt_features, src_kps, trg_kps,\n",
    "                               src_original_size, tgt_original_size, img_size, patch_size, temperature=10.0):\n",
    "    \"\"\"\n",
    "    Compute cross-entropy loss for semantic correspondence.\n",
    "    Treats correspondence as a classification problem where each target patch is a class.\n",
    "\n",
    "    Args:\n",
    "        src_features: [1, H, W, D] source dense features\n",
    "        tgt_features: [1, H, W, D] target dense features\n",
    "        src_kps: [N, 2] source keypoints in pixel coordinates\n",
    "        trg_kps: [N, 2] target keypoints in pixel coordinates\n",
    "        src_original_size: (width, height) of original source image\n",
    "        tgt_original_size: (width, height) of original target image\n",
    "        img_size: resizing size used during feature extraction\n",
    "        patch_size: size of each patch\n",
    "        temperature: softmax temperature (higher = more peaked distribution)\n",
    "\n",
    "    Returns:\n",
    "        loss: mean cross-entropy loss across all keypoints\n",
    "    \"\"\"\n",
    "    _, H, W, D = tgt_features.shape\n",
    "    tgt_flat = tgt_features.reshape(H * W, D)  # [H*W, D]\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for i in range(src_kps.shape[0]):\n",
    "        src_x, src_y = src_kps[i]\n",
    "        tgt_x, tgt_y = trg_kps[i]\n",
    "\n",
    "        # Get source feature at keypoint location\n",
    "        src_patch_x, src_patch_y = pixel_to_patch_coord(src_x, src_y, src_original_size, patch_size=patch_size, resized_size=img_size)\n",
    "        src_feature = src_features[0, src_patch_y, src_patch_x, :]  # [D]\n",
    "\n",
    "        # Get ground truth target patch coordinates\n",
    "        tgt_patch_x, tgt_patch_y = pixel_to_patch_coord(tgt_x, tgt_y, tgt_original_size, patch_size=patch_size, resized_size=img_size)\n",
    "        # Compute cosine similarities with all target patches\n",
    "        similarities = F.cosine_similarity(\n",
    "            src_feature.unsqueeze(0),  # [1, D]\n",
    "            tgt_flat,  # [H*W, D]\n",
    "            dim=1\n",
    "        )  # [H*W]\n",
    "\n",
    "        # Convert similarities to log-probabilities\n",
    "        log_probs = F.log_softmax(similarities * temperature, dim=0)\n",
    "\n",
    "        # Ground truth index (flatten 2D coordinates to 1D)\n",
    "        gt_idx = tgt_patch_y * W + tgt_patch_x\n",
    "\n",
    "        # Negative log-likelihood loss\n",
    "        loss = -log_probs[gt_idx]\n",
    "        losses.append(loss)\n",
    "\n",
    "    return torch.stack(losses).mean()\n",
    "\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, scaler, device, epoch, img_size, patch_size, temperature=10.0):\n",
    "    \"\"\"\n",
    "    Train for one epoch with Automatic Mixed Precision (AMP).\n",
    "\n",
    "    Args:\n",
    "        model: SAM model\n",
    "        dataloader: training data loader\n",
    "        optimizer: optimizer\n",
    "        scaler: torch.cuda.amp.GradScaler for mixed precision\n",
    "        device: 'cuda' or 'cpu'\n",
    "        epoch: current epoch number\n",
    "        img_size: size to which images are resized for feature extraction\n",
    "        patch_size: size of each patch\n",
    "        temperature: softmax temperature for loss\n",
    "\n",
    "    Returns:\n",
    "        avg_loss: average loss over the epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    for idx, sample in enumerate(dataloader):\n",
    "        # Prepare data\n",
    "        src_tensor = sample['src_img'].to(device)  # [1, 3, H, W]\n",
    "        tgt_tensor = sample['trg_img'].to(device)  # [1, 3, H, W]\n",
    "\n",
    "        # Resize to 518x518 (DINOv2 expects this size)\n",
    "        src_tensor = F.interpolate(src_tensor, size=(img_size, img_size), mode='bilinear', align_corners=False)\n",
    "        tgt_tensor = F.interpolate(tgt_tensor, size=(img_size, img_size), mode='bilinear', align_corners=False)\n",
    "\n",
    "        # Store original sizes for coordinate conversion\n",
    "        src_original_size = (sample['src_imsize'][2], sample['src_imsize'][1])\n",
    "        tgt_original_size = (sample['trg_imsize'][2], sample['trg_imsize'][1])\n",
    "\n",
    "        # Get keypoints\n",
    "        src_kps = sample['src_kps'].numpy()[0]  # [N, 2]\n",
    "        trg_kps = sample['trg_kps'].numpy()[0]  # [N, 2]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Autocast operations to appropriate precision\n",
    "        with torch.cuda.amp.autocast():\n",
    "            # Extract dense features\n",
    "            src_features = extract_dense_features_SAM(model, src_tensor, image_size=img_size, training=True)\n",
    "            tgt_features = extract_dense_features_SAM(model, tgt_tensor, image_size=img_size, training=True)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = compute_cross_entropy_loss(\n",
    "                src_features, tgt_features,\n",
    "                src_kps, trg_kps,\n",
    "                src_original_size, tgt_original_size,\n",
    "                img_size, patch_size,\n",
    "                temperature=temperature\n",
    "            )\n",
    "\n",
    "        # Backward pass with GradScaler\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "        # Print progress\n",
    "        if (idx + 1) % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Batch {idx + 1}/{len(dataloader)}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main training and evaluation pipeline\"\"\"\n",
    "\n",
    "    # ========== CONFIGURATION ==========+\n",
    "    n_blocks = 2  #to try: 1, 2, 3, 4\n",
    "    num_epochs = 1\n",
    "    learning_rate = 1e-4\n",
    "    batch_size = 1  #SPair-71k has variable-sized images\n",
    "    temperature = 5  #softmax temperature for cross-entropy loss try 5,10,15\n",
    "    img_size = 512\n",
    "    patch_size = 16\n",
    "    weight_decay = 0.01\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Create results_SPair71k directory with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    results_dir = f'results_colab/SAM/lr_{learning_rate}_t_{temperature}_blocks_{n_blocks}_{timestamp}'\n",
    "    # results_dir = f'results_SPair71k/dinov3_base_finetuned_{timestamp}'\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    print(f\"Results will be saved to: {results_dir}\")\n",
    "\n",
    "    # ========== LOAD DATASETS ==========\n",
    "    print(\"\\nLoading SPair-71k dataset...\")\n",
    "    pair_ann_path = f'{base}/PairAnnotation'\n",
    "    layout_path = f'{base}/Layout'\n",
    "    image_path = f'{base}/JPEGImages'\n",
    "    dataset_size = 'large'\n",
    "    pck_alpha = 0.1 #mock, it's not used in evaluation\n",
    "\n",
    "    train_dataset = SPairDataset(\n",
    "        pair_ann_path,\n",
    "        layout_path,\n",
    "        image_path,\n",
    "        dataset_size,\n",
    "        pck_alpha,  # dummy pck_alpha, not used during training\n",
    "        datatype='trn'  # training split\n",
    "    )\n",
    "\n",
    "    val_dataset = SPairDataset(\n",
    "        pair_ann_path,\n",
    "        layout_path,\n",
    "        image_path,\n",
    "        dataset_size,\n",
    "        pck_alpha,\n",
    "        datatype='val'\n",
    "    )\n",
    "\n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Val samples: {len(val_dataset)}\")\n",
    "\n",
    "    # Create data loader\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=1,\n",
    "        pin_memory=True if device == 'cuda' else False\n",
    "    )\n",
    "\n",
    "    # for n_blocks in [1,2,3,4]:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"FINETUNING WITH LAST {n_blocks} BLOCKS UNFROZEN\")\n",
    "    print(\"=\" * 80)\n",
    "    # ========== LOAD MODEL ==========\n",
    "    print(\"\\nLoading SAM model...\")\n",
    "    model_type = \"vit_b\"\n",
    "    checkpoint_path = \"models/segment_anything/weights/sam_vit_b_01ec64.pth\"\n",
    "    sam_model = sam_model_registry[model_type](checkpoint=checkpoint_path)\n",
    "    sam_model.to(device)\n",
    "\n",
    "    # freeze entire model, then unfreeze last N blocks\n",
    "    freeze_model(sam_model)\n",
    "    unfreeze_last_n_blocks(sam_model, n_blocks)\n",
    "\n",
    "    # count trainable parameters\n",
    "    trainable_params = sum(p.numel() for p in sam_model.parameters() if p.requires_grad)\n",
    "    total_params = sum(p.numel() for p in sam_model.parameters())\n",
    "    print(f\"\\nTrainable parameters: {trainable_params:,} / {total_params:,} \"\n",
    "            f\"({100 * trainable_params / total_params:.2f}%)\")\n",
    "\n",
    "\n",
    "    # ========== OPTIMIZER AND GRAD SCALER ==========\n",
    "    optimizer = optim.AdamW(\n",
    "        filter(lambda p: p.requires_grad, sam_model.parameters()),\n",
    "        lr=learning_rate,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    # Initialize GradScaler for Automatic Mixed Precision\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    # Optional: Learning rate scheduler\n",
    "    # scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "    # ========== TRAINING LOOP ==========\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"STARTING TRAINING\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # best_pck = -1.0\n",
    "    # best_epoch = -1\n",
    "    training_history = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\n{'=' * 60}\")\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print('=' * 60)\n",
    "\n",
    "        # Train for one epoch\n",
    "        train_loss = train_epoch(\n",
    "            sam_model, train_loader, optimizer, scaler, device, epoch + 1, img_size, patch_size, temperature=temperature\n",
    "        )\n",
    "        print(f\"\\nAverage training loss: {train_loss:.4f}\")\n",
    "\n",
    "        # Update learning rate\n",
    "        # scheduler.step()\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Learning rate: {current_lr:.6f}\")\n",
    "\n",
    "        # Validate on val set\n",
    "        print(\"\\nEvaluating on test set...\")\n",
    "        # For evaluation, you typically don't use autocast as it's not about speed but accuracy.\n",
    "        # However, for consistency, if the model was trained with AMP, it might be beneficial\n",
    "        # to also run evaluation with autocast for feature extraction, but it's not strictly necessary.\n",
    "        # We'll keep it as FP32 evaluation to ensure robustness.\n",
    "        sam_model.eval() # Set model to evaluation mode\n",
    "        with torch.no_grad(): # No gradients needed for evaluation\n",
    "            results_val, per_image_metrics = simple_evaluate_SAM(sam_model, val_dataset, device, img_size, patch_size)\n",
    "\n",
    "        pck_005 = results_val['pck@0.05']['mean']\n",
    "        pck_010 = results_val['pck@0.10']['mean']\n",
    "        pck_020 = results_val['pck@0.20']['mean']\n",
    "\n",
    "        print(f\"Val Results:\")\n",
    "        print(f\"  PCK@0.05: {pck_005:.2f}%\")\n",
    "        print(f\"  PCK@0.10: {pck_010:.2f}%\")\n",
    "        print(f\"  PCK@0.20: {pck_020:.2f}%\")\n",
    "\n",
    "\n",
    "        # Save model checkpoint\n",
    "        # Save checkpoint for this epoch\n",
    "        ckpt_path = f'{results_dir}/epoch_{epoch + 1}.pth'\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': sam_model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'n_blocks': n_blocks,\n",
    "            'temperature': temperature,\n",
    "            'learning_rate': learning_rate,\n",
    "            'val_pck@0.05': pck_005,\n",
    "            'val_pck@0.10': pck_010,\n",
    "            'val_pck@0.20': pck_020,\n",
    "        }, ckpt_path)\n",
    "        print(f\"\\u2713 Checkpoint saved: {ckpt_path}\")\n",
    "\n",
    "        # Track best by PCK@0.10\n",
    "        # if pck_010 > best_pck:\n",
    "        #     best_pck = pck_010\n",
    "        #     best_epoch = epoch + 1\n",
    "        #     best_ckpt_path = f'{results_dir}/best_model.pth'\n",
    "        #     torch.save({\n",
    "        #         'epoch': best_epoch,\n",
    "        #         'model_state_dict': model.state_dict(),\n",
    "        #         'optimizer_state_dict': optimizer.state_dict(),\n",
    "        #         'n_blocks': n_blocks,\n",
    "        #         'temperature': temperature,\n",
    "        #         'learning_rate': learning_rate,\n",
    "        #         'val_pck@0.05': pck_005,\n",
    "        #         'val_pck@0.10': pck_010,\n",
    "        #         'val_pck@0.20': pck_020,\n",
    "        #     }, best_ckpt_path)\n",
    "        #     print(f\"\\u2713 Best model saved: {best_ckpt_path}\")\n",
    "\n",
    "        # Store training history\n",
    "        training_history.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': train_loss,\n",
    "            'learning_rate': current_lr,\n",
    "            'val_pck@0.05': pck_005,\n",
    "            'val_pck@0.10': pck_010,\n",
    "            'val_pck@0.20': pck_020,\n",
    "        })\n",
    "\n",
    "        # Save intermediate results_SPair71k\n",
    "        # with open(f'{results_dir}/training_history.json', 'w') as f:\n",
    "        #     json.dump(training_history, f, indent=2)\n",
    "\n",
    "        # ========== FINAL RESULTS ==========\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"TRAINING COMPLETED\")\n",
    "        print(\"=\" * 60)\n",
    "        # print(f\"Best PCK@0.1: {best_pck:.2f}% (Epoch {best_epoch})\")\n",
    "        print(f\"Results saved to: {results_dir}\")\n",
    "\n",
    "\n",
    "        # Save metadata for comparison\n",
    "        metadata = {\n",
    "            'n_blocks': n_blocks,\n",
    "            'temperature': temperature,\n",
    "            'learning_rate': learning_rate,\n",
    "            'num_epochs': num_epochs,\n",
    "            # 'best_epoch': best_epoch,\n",
    "            # 'best_pck@0.05': float(training_history[best_epoch - 1]['val_pck@0.05']),\n",
    "            # 'best_pck@0.10': float(best_pck),\n",
    "            # 'best_pck@0.20': float(training_history[best_epoch - 1]['val_pck@0.20']),\n",
    "            'pck@0.05': float(training_history[-1]['val_pck@0.05']),\n",
    "            'pck@0.10': float(training_history[-1]['val_pck@0.10']),\n",
    "            'pck@0.20': float(training_history[-1]['val_pck@0.20']),\n",
    "            'training_history': training_history,\n",
    "        }\n",
    "\n",
    "        with open(f'{results_dir}/metadata.json', 'w') as f:\n",
    "            json.dump(metadata, f, indent=2)\n",
    "        print(f\"\\u2713 Metadata saved: {results_dir}/metadata.json\")\n",
    "\n",
    "    # Automatically copy results to Google Drive\n",
    "    drive_results_base_path = '/content/drive/MyDrive/Colab_SAM_finetuning_temp_validation_results/'\n",
    "    drive_destination_path = os.path.join(drive_results_base_path, os.path.basename(results_dir))\n",
    "\n",
    "    try:\n",
    "        if not os.path.exists(drive_results_base_path):\n",
    "            os.makedirs(drive_results_base_path, exist_ok=True)\n",
    "        shutil.copytree(results_dir, drive_destination_path)\n",
    "        print(f\"\\n\\u2713 Successfully copied results to Google Drive: {drive_destination_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n\\u2717 Error copying results to Google Drive: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c2f11d",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "aborted",
     "timestamp": 1768499780879,
     "user": {
      "displayName": "Simone Iachino",
      "userId": "17661475359145447135"
     },
     "user_tz": -60
    },
    "id": "c5c2f11d"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Smonta il Drive\n",
    "drive.flush_and_unmount()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
